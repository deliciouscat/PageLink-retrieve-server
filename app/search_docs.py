"""
ë¬¸ì„œ ê²€ìƒ‰ ëª¨ë“ˆ
"""
import asyncio
import os
from jinja2 import Environment, FileSystemLoader
from pydantic import BaseModel, Field
from typing import List

from app.retrieve.api_search.natural_search import from_openrouter
from app.retrieve.api_search.keyword_search import from_ddgs
from app.llm.inference import structured_inference

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ templates í´ë” ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
template_dir = os.path.join(current_dir, 'llm')
env = Environment(loader=FileSystemLoader(template_dir))
    
class QueriesResponse(BaseModel):
    """ì—¬ëŸ¬ ì§ˆë¬¸ë“¤ì„ ë‹´ëŠ” ì‘ë‹µ ëª¨ë¸"""
    queries: List[str] = Field(description="ìƒì„±ëœ ì¿¼ë¦¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸", min_items=2, max_items=6)

async def question_merging(question_list: List[str]):
    """
    ë¬¸ì„œ ì¸ë±ì‹± í•¨ìˆ˜ - pydantic-ai êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‚¬ìš©
    doc_inputì„ ë°›ì•„ì„œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±
    """
    print(f"ğŸ” [question_merging] ì‹œì‘ - User: {question_list}")
    
    template = env.get_template('prompts/question_merging_250911.jinja')
    prompt = template.render(question_list=question_list)
    
    # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ ìƒˆë¡œìš´ inference í•¨ìˆ˜ ì‚¬ìš©
    result = await structured_inference(
        prompt=prompt,
        # structured outputì€ ì œí•œëœ ëª¨ë¸ë§Œ ê°€ëŠ¥:
        # - gpt-4 ê³„ì—´, gemini-2.5 ê³„ì—´
        # - ë¶ˆê°€ëŠ¥í•œ ëª¨ë¸: gpt-5 ê³„ì—´, grok-3 ê³„ì—´
        #model_name="google/gemini-2.5-flash-lite",
        model_name="openai/gpt-4.1-mini",
        model_settings={
            "temperature": 0.8,
            "max_tokens": 1000,
        },
        output_type=QueriesResponse  # êµ¬ì¡°í™”ëœ ì¶œë ¥ íƒ€ì… ì§€ì •
    )

    # result.outputì´ ì´ë¯¸ QuestionsResponse ê°ì²´ì„
    queries_response = result.output
    
    print(f"âœ… [question_merging] ì™„ë£Œ - User: {question_list}")

    
    return {
        "queries": queries_response.queries
    }

async def search_single_question(question: str):
    """ë‹¨ì¼ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ìˆ˜í–‰"""
    try:
        # ê²€ìƒ‰ ì—”ì§„ ì„ íƒ: ì•„ë˜ ì¤‘ í•˜ë‚˜ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©
        loop = asyncio.get_event_loop()
        
        # ì˜µì…˜ 1: ìì—°ì–´ ê²€ìƒ‰ (Perplexity/OpenRouter ê¸°ë°˜)
        #search_result = await loop.run_in_executor(None, from_openrouter, question, True)
        
        # ì˜µì…˜ 2: í‚¤ì›Œë“œ ê²€ìƒ‰ (DuckDuckGo ê¸°ë°˜)
        search_result = await loop.run_in_executor(None, from_ddgs, question, True)
        
        return search_result.urls
    except Exception as e:
        print(f"âš ï¸ [search_docs] ê²€ìƒ‰ ì‹¤íŒ¨: {question} - {str(e)}")
        return []

async def search_docs(data_instance):
    """
    ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜
    expand_collection_query ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰
    expand_collection_query -> search_docs ìˆœì„œ ì˜ì¡´ì„±
    """
    print(f"ğŸ” [search_docs] ì‹œì‘ - User: {data_instance.user_id}")
    
    # collection_questionì´ ìˆëŠ”ì§€ í™•ì¸ (ì˜ì¡´ì„± ì²´í¬)
    if not (hasattr(data_instance, 'collection_question') and data_instance.collection_question):
        print(f"âš ï¸ [search_docs] collection_questionì´ ì—†ìŒ - User: {data_instance.user_id}")
        return []
    
    # ëª¨ë“  ì§ˆë¬¸ì„ ë³‘ë ¬ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    questions = [q.get('question') for q in data_instance.collection_question.get('questions')]

    # ì§ˆë¬¸ ëª©ë¡ì„ ì¿¼ë¦¬ ëª©ë¡ìœ¼ë¡œ ë³€í™˜
    queries_result = await question_merging(questions)
    queries = queries_result["queries"]
    print(f"ğŸ” [search_docs] ì¿¼ë¦¬ ëª©ë¡: {queries}")
    
    search_tasks = [
        search_single_question(query) 
        for query in queries
    ]
    
    # ë³‘ë ¬ ì‹¤í–‰
    results = await asyncio.gather(*search_tasks)
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
    all_urls = []
    for urls in results:
        all_urls.extend(urls)
    
    unique_urls = list(set(all_urls))
    
    print(f"âœ… [search_docs] ì™„ë£Œ - User: {data_instance.user_id}, ê²°ê³¼: {len(unique_urls)}ê°œ")
    return unique_urls
