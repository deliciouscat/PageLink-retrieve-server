"""
ë¬¸ì„œ ìš”ì•½ ëª¨ë“ˆ
"""
import os
import asyncio
import random
from app.llm.inference import inference
from jinja2 import Environment, FileSystemLoader


# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ templates í´ë” ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
template_dir = os.path.join(current_dir, 'llm')
env = Environment(loader=FileSystemLoader(template_dir))

async def doc_summary(data_instance):
    """
    ì œì–´ ë³€ìˆ˜:
    ëª¨ë¸, configs, system_prompt
    """
    print(f"ğŸ“ [doc_summary] ì‹œì‘ - User: {data_instance.user_id}")
    # í…œí”Œë¦¿ ë Œë”ë§
    template = env.get_template('prompts/doc_summary_250828.jinja')
    system_prompt = template.render(doc_input=data_instance.doc_input)
    
    result = await inference(
        prompt=data_instance.doc_input,  # promptì™€ system_prompt ìˆœì„œ ìˆ˜ì •
        model_name="google/gemma-3-27b-it",
        model_settings={
            "temperature": 0.6,
            "max_tokens": 1000,
        },
        system_prompt=system_prompt
    )
    
    summary = result.output
    print(f"âœ… [doc_summary] ì™„ë£Œ - User: {data_instance.user_id}")
    return summary