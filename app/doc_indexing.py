"""
ë¬¸ì„œ ì¸ë±ì‹± ëª¨ë“ˆ - pydantic-ai êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‚¬ìš©
"""
import os
import asyncio
import random
from app.llm.inference import structured_inference
from jinja2 import Environment, FileSystemLoader
from pydantic import BaseModel, Field
from typing import List


# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ templates í´ë” ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
template_dir = os.path.join(current_dir, 'llm')
env = Environment(loader=FileSystemLoader(template_dir))

# ê¸°ì¡´ str_to_json í•¨ìˆ˜ëŠ” parser ëª¨ë“ˆë¡œ ì´ë™
# from app.llm.parser import json_parser as str_to_json  # í•˜ìœ„ í˜¸í™˜ì„±

class Question(BaseModel):
    """ìƒì„±ëœ ì§ˆë¬¸ì„ ë‚˜íƒ€ë‚´ëŠ” ëª¨ë¸"""
    question: str = Field(description="ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ì§ˆë¬¸")
    answer: str = Field(description="ìƒì„±ëœ ì§ˆë¬¸ì˜ ë‹µë³€")
    

class QuestionsResponse(BaseModel):
    """ì—¬ëŸ¬ ì§ˆë¬¸ë“¤ì„ ë‹´ëŠ” ì‘ë‹µ ëª¨ë¸"""
    questions: List[Question] = Field(description="ìƒì„±ëœ ì§ˆë¬¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸", min_items=2, max_items=6)

async def doc_indexing(data_instance):
    """
    ë¬¸ì„œ ì¸ë±ì‹± í•¨ìˆ˜ - pydantic-ai êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‚¬ìš©
    doc_inputì„ ë°›ì•„ì„œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±
    """
    print(f"ğŸ” [doc_indexing] ì‹œì‘ - User: {data_instance.user_id}")
    
    template = env.get_template('prompts/doc_indexing_250830.jinja')
    system_prompt = template.render(doc_input=data_instance.doc_input, memopad=data_instance.collection_memo)
    
    # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ ìƒˆë¡œìš´ inference í•¨ìˆ˜ ì‚¬ìš©
    result = await structured_inference(
        prompt=data_instance.doc_input,
        # structured outputì€ ì œí•œëœ ëª¨ë¸ë§Œ ê°€ëŠ¥:
        # - gpt-4 ê³„ì—´, gemini-2.5 ê³„ì—´
        # - ë¶ˆê°€ëŠ¥í•œ ëª¨ë¸: gpt-5 ê³„ì—´, grok-3 ê³„ì—´
        model_name="google/gemini-2.5-flash-lite",
        #model_name="openai/gpt-4.1-nano",
        model_settings={
            "temperature": 0.75,
            "max_tokens": 1000,
        },
        system_prompt=system_prompt,
        output_type=QuestionsResponse  # êµ¬ì¡°í™”ëœ ì¶œë ¥ íƒ€ì… ì§€ì •
    )
    
    # raw result ì¶œë ¥
    print(result)
    
    # result.outputì´ ì´ë¯¸ QuestionsResponse ê°ì²´ì„
    questions_response = result.output
    
    print(f"âœ… [doc_indexing] ì™„ë£Œ - User: {data_instance.user_id}")

    
    return {
        "questions": [q.model_dump() for q in questions_response.questions]
    }
    

